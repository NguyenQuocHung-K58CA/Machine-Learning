{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 17\n",
      "=== Post 0 with dist=1.41: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=0.86: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=0.86: Most imaging databases safe images permanently.\n",
      "=== Post 3 with dist=0.77: Imaging databases store images.\n",
      "=== Post 4 with dist=0.77: Imaging databases store images. Imaging databases store images. Imaging databases store images.\n",
      "Best post is 3 with dist=0.77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'get'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk.stem \n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 1, stop_words='english')\n",
    "\n",
    "# content = [\"How to use this algorithm\", \"How are you right?\"]\n",
    "\n",
    "# X = vectorizer.fit_transform(content)\n",
    "# print X.toarray()\n",
    "# print vectorizer.get_feature_names()\n",
    "\n",
    "# DIR = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"data\")\n",
    "# print DIR\n",
    "# posts = [open(os.path.join(DIR, f)).read() for f in os.listdir(DIR)]\n",
    "\n",
    "posts = [\"This is a toy post about machine learning. Actually, it contains not much interesting stuff.\",\n",
    "\"Imaging databases provide storage capabilities.\",\n",
    "\"Most imaging databases safe images permanently.\",\n",
    "\"Imaging databases store images.\",\n",
    "\"Imaging databases store images. Imaging databases store images. Imaging databases store images.\"]\n",
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples, num_features = X_train.shape\n",
    "\n",
    "print num_samples, num_features\n",
    "\n",
    "new_post = \"imaging databases\"\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "\n",
    "def dist_norm(v1, v2):\n",
    "    v1_normalized = v1/sp.linalg.norm(v1.toarray())\n",
    "    v2_normalized = v2/sp.linalg.norm(v2.toarray())\n",
    "    delta = v1_normalized - v2_normalized\n",
    "    return sp.linalg.norm(delta.toarray())\n",
    "\n",
    "best_doc = None\n",
    "best_dist = sys.maxint\n",
    "best_i = None\n",
    "for i in range(0, num_samples):\n",
    "    post = posts[i]\n",
    "    if post==new_post:\n",
    "        continue\n",
    "    post_vec = X_train.getrow(i)\n",
    "    dist = dist_norm(post_vec, new_post_vec)\n",
    "    print \"=== Post %i with dist=%.2f: %s\"%(i, dist, post)\n",
    "    if dist<best_dist:\n",
    "        best_dist = dist\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\"%(best_i, best_dist))\n",
    "\n",
    "s = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
